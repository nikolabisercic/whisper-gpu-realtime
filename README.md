# ğŸ¤ GPU-Accelerated Speech-to-Text with Whisper

Real-time speech-to-text using OpenAI Whisper with **NVIDIA GPU acceleration** on Ubuntu.

## ğŸš€ Quickstart (2 minutes)

```bash
# 1. Activate your virtual environment
source ~/envs/text2speach/bin/activate

# 2. Run with GPU acceleration
./gpu_launcher.sh --model small --device cuda

# 3. Speak into your microphone!
# Transcriptions appear as: â†’ your speech here
# Press Ctrl+C to stop
```

## âœ¨ Features

- **Real-time transcription** from microphone (not file upload)
- **GPU acceleration** with your RTX 4060 (4-6x faster than CPU)
- **Multiple models** from tiny (fastest) to medium (most accurate)
- **Clear GPU/CPU indicators** - know exactly what's running
- **Automatic fallback** to CPU if GPU fails

## ğŸ“Š System Status

- âœ… **GPU**: NVIDIA RTX 4060 Laptop (8GB VRAM)
- âœ… **CUDA**: Version 12.4
- âœ… **Models**: tiny, base, small, medium (all downloaded)
- âœ… **Libraries**: faster-whisper 1.0.3, ctranslate2 4.6.0

## ğŸ¯ Model Selection Guide

| Model | Speed | Accuracy | VRAM | Recommended For |
|-------|-------|----------|------|-----------------|
| **tiny** | âš¡âš¡âš¡âš¡âš¡ | â­â­ | 1GB | Testing, casual use |
| **base** | âš¡âš¡âš¡âš¡ | â­â­â­ | 1.5GB | Daily use |
| **small** | âš¡âš¡âš¡ | â­â­â­â­ | 2.5GB | **Best balance** âœ¨ |
| **medium** | âš¡âš¡ | â­â­â­â­â­ | 5GB | High accuracy |

## ğŸ› ï¸ Installation Complete

All dependencies are installed. No additional setup needed!

## ğŸ“ Project Structure

```
text2speach/
â”œâ”€â”€ gpu_launcher.sh         # ğŸš€ Main launcher (USE THIS!)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ speech_to_text.py   # Core implementation
â”œâ”€â”€ scripts/               
â”‚   â”œâ”€â”€ launch_gpu.py       # Alternative launcher
â”‚   â””â”€â”€ download_models.py  # Model downloader
â”œâ”€â”€ tests/                  # Test scripts
â”œâ”€â”€ recordings/             # Saved audio files
â””â”€â”€ README.md              # This file
```

## ğŸ® Usage Examples

### Basic Usage (Recommended)
```bash
./gpu_launcher.sh --model small --device cuda
```

### Try Different Models
```bash
# Fastest (for testing)
./gpu_launcher.sh --model tiny --device cuda

# Most accurate
./gpu_launcher.sh --model medium --device cuda
```

### Force CPU Mode
```bash
./gpu_launcher.sh --model tiny --device cpu
```

## ğŸ”§ Troubleshooting

### GPU Not Working?

1. **Use the launcher**: Always use `./gpu_launcher.sh` - it sets up the environment correctly
2. **Check GPU status**: Run `nvidia-smi` to verify GPU is available
3. **Library errors**: The launcher handles this automatically

### Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| "Unable to load libcudnn_ops" | Use `./gpu_launcher.sh` instead of `python` directly |
| GPU not detected | Check `nvidia-smi`, restart terminal |
| Slow performance | Ensure using `--device cuda`, not `cpu` |
| No transcription | Speak louder, check microphone with `python tests/test_microphone.py` |

## ğŸ¯ Performance Tips

1. **Use GPU**: Always use `--device cuda` for 4-6x faster transcription
2. **Model choice**: Start with `small` for best speed/accuracy balance
3. **Microphone**: Speak clearly, avoid background noise
4. **Chunk size**: Default 5-second chunks work well

## ğŸ§ª Testing

```bash
# Test microphone
python tests/test_microphone.py

# Test GPU setup
python test_gpu_simple.py
```

## ğŸ“ Notes

- **Real-time**: Processes audio in 5-second chunks
- **Language**: Default is English (change with `language` parameter in code)
- **GPU Memory**: Your RTX 4060 can handle all models except large
- **Fallback**: Automatically uses CPU if GPU fails (with clear warnings)

## ğŸ‰ Success!

You now have GPU-accelerated speech-to-text working! The system transcribes your voice in real-time using your RTX 4060 GPU for maximum performance.

---

*Built with â¤ï¸ using faster-whisper and NVIDIA CUDA*